{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Four: Neural networks </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a neural network classifier using an architecture of your choosing. This application\n",
    "of deep learning can be done in PyTorch, TensorFlow, or a framework of your choice. This is the\n",
    "industry standard for image classification. Describe your network and assess its performance. To\n",
    "receive extra credit, your neural network classifier must outperform your other methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from datainput import *\n",
    "from preprocess import *\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_path = './20_categories_training/'\n",
    "# val_path = './20_Validation/'\n",
    "# try not to printout train_data['Pictures'] directly, takes a while\n",
    "train_data = read_train_data(train_path)\n",
    "# test_data = read_test_data(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 300, 400, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 300, 400, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 150, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 150, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 75, 100, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 75, 100, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 38, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 38, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 19, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 19, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 10, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                532544    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 607,425\n",
      "Trainable params: 607,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Reshape\n",
    "from keras.regularizers import l1\n",
    "from keras.models import Model\n",
    "\n",
    "def NN(inputshape = (300,400,3), l = 1e-6):\n",
    "    \n",
    "    regularizer_strength = l\n",
    "    input_img = Input(shape=inputshape)  # y, x\n",
    "    x = Conv2D(32, (3, 3), activation='relu', \n",
    "            padding='same', activity_regularizer=l1(regularizer_strength))(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', \n",
    "            padding='same', activity_regularizer=l1(regularizer_strength))(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', \n",
    "            padding='same', activity_regularizer=l1(regularizer_strength))(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', \n",
    "            padding='same', activity_regularizer=l1(regularizer_strength))(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', \n",
    "            padding='same', activity_regularizer=l1(regularizer_strength))(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(20, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input_img, output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    \"\"\"Split data into training and testing(validation)\"\"\"\n",
    "    n, d = df.shape\n",
    "    shuffled = np.arange(n)\n",
    "    np.random.shuffle(shuffled)\n",
    "    train_n = int(n*0.8)\n",
    "    test_n = n-train_n\n",
    "    train_idx = shuffled[:train_n]\n",
    "    test_idx = shuffled[train_n:]\n",
    "    return df.iloc[train_idx,:d-1], df.iloc[train_idx,d-1], df.iloc[test_idx,:d-1], df.iloc[test_idx,d-1]\n",
    "    \n",
    "def accuracy(pred, actual):\n",
    "    return np.sum(pred==actual)/len(pred)\n",
    "\n",
    "def add_dimension(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return np.stack([image,image,image], axis = -1)\n",
    "    return image\n",
    "\n",
    "def cnn_feature_frame(df):\n",
    "    # input original training_data set\n",
    "    FE = feature_extract()\n",
    "    images = df.Pictures\n",
    "    # trim all images\n",
    "    print('Trim all images..')\n",
    "    images = FE.trim_all(images)\n",
    "    df_X = pd.DataFrame()\n",
    "    # convert all images to same size first 400x300\n",
    "    images = pd.Series(images.apply(lambda x: FE.resize_image(x, 400, 300)))\n",
    "    df_X['Pictures'] = images.apply(add_dimension)\n",
    "    \n",
    "    if 'Encoding' in df.columns:\n",
    "        df_X['Encoding'] = df.Encoding\n",
    "    return df_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = train_data[train_data.Pictures.apply(lambda x: len(x.shape)==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trim all images..\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_split(cnn_feature_frame(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
